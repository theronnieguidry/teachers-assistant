# Server
PORT=3001
NODE_ENV=development

# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# AI Providers
# Set AI_PROVIDER to choose: openai (premium cloud) or ollama/local (free local).
# Legacy value "claude" is still accepted and remapped to openai.
AI_PROVIDER=openai

# Cloud providers (require API keys)
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_KEY=your-openai-api-key

# Ollama (free local LLM - backend-managed model policy)
# Install: https://ollama.com/download
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_PRIMARY_MODEL=llama3.1:8b
OLLAMA_FALLBACK_MODELS=qwen2.5:7b,gemma3:4b,llama3.2
OLLAMA_AUTO_PULL=true
OLLAMA_WARMUP_TIMEOUT_MS=180000

# Optional override for prompt polishing only.
# When unset, polishing uses the same backend-resolved local model as generation.
# POLISH_MODEL=llama3.1:8b
