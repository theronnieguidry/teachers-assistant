# Server
PORT=3001
NODE_ENV=development

# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# AI Providers
# Set AI_PROVIDER to choose: claude, openai, or ollama
AI_PROVIDER=claude

# Cloud providers (require API keys)
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_KEY=your-openai-api-key

# Ollama (free local LLM - no API key needed)
# Install: https://ollama.com/download
# Then run: ollama pull llama3.2 && ollama serve
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
